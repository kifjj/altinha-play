{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Batch Process Altinha Videos\n",
        "\n",
        "This notebook processes multiple altinha videos using the reusable function from `altinha_processor.py`.\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/kifjj/altinha-play/blob/main/batch_process_videos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install \"numpy<2.0\" \"scipy<1.14\" supervision ultralytics \"opencv-python-headless<4.12\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Processing Module\n",
        "\n",
        "Upload `altinha_processor.py` to this environment, then import the processing function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the processing function\n",
        "# Make sure altinha_processor.py is uploaded to the working directory\n",
        "from altinha_processor import process_altinha_video\n",
        "\n",
        "# Alternatively, download from GitHub:\n",
        "# !wget https://raw.githubusercontent.com/kifjj/altinha-play/main/altinha_processor.py\n",
        "# from altinha_processor import process_altinha_video\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Additional Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "Set up model paths and output directories.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model paths (shared across all videos)\n",
        "BALL_MODEL_PATH = '/kaggle/input/yolo-ft-2511/pytorch/default/1/altinha_best.pt'\n",
        "POSE_MODEL_PATH = '/kaggle/input/yolo11-pose/pytorch/default/1/yolo11l-pose.pt'\n",
        "\n",
        "# Output directories\n",
        "OUTPUT_DIR = '/kaggle/working/batch_results'\n",
        "DEBUG_FRAMES_DIR = '/kaggle/working/debug_frames'\n",
        "\n",
        "# Create output directories\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(DEBUG_FRAMES_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"‚úÖ Output directory: {OUTPUT_DIR}\")\n",
        "print(f\"‚úÖ Debug frames directory: {DEBUG_FRAMES_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Video List\n",
        "\n",
        "Define the array of video paths to process. **Update this list with your video paths!**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of video paths to process\n",
        "# Update this array with your video file paths\n",
        "VIDEO_PATHS = [\n",
        "    '/kaggle/input/alta-videos/altinha-beach-green-mq-13s.mp4',\n",
        "    '/kaggle/input/alta-videos/altinha-beach-dark-mq-20s.mp4',\n",
        "    # Add more video paths here...\n",
        "    # '/kaggle/input/alta-videos/video3.mp4',\n",
        "    # '/kaggle/input/alta-videos/video4.mp4',\n",
        "]\n",
        "\n",
        "print(f\"üìπ Found {len(VIDEO_PATHS)} videos to process:\")\n",
        "for i, video_path in enumerate(VIDEO_PATHS, 1):\n",
        "    print(f\"   {i}. {os.path.basename(video_path)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Process All Videos\n",
        "\n",
        "Loop through all videos and process them one by one.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Store results for all videos\n",
        "all_results = []\n",
        "\n",
        "print(\"\\n\" + \"#\"*80)\n",
        "print(\"#\" + \" \"*78 + \"#\")\n",
        "print(f\"#  BATCH PROCESSING {len(VIDEO_PATHS)} VIDEOS\".ljust(79) + \"#\")\n",
        "print(\"#\" + \" \"*78 + \"#\")\n",
        "print(\"#\"*80 + \"\\n\")\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "for idx, video_path in enumerate(VIDEO_PATHS, 1):\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"VIDEO {idx}/{len(VIDEO_PATHS)}: {os.path.basename(video_path)}\")\n",
        "    print(f\"{'='*80}\")\n",
        "    \n",
        "    try:\n",
        "        # Generate output path\n",
        "        video_basename = os.path.splitext(os.path.basename(video_path))[0]\n",
        "        output_video_path = os.path.join(OUTPUT_DIR, f\"{video_basename}_annotated.mp4\")\n",
        "        \n",
        "        # Create video-specific debug directory\n",
        "        video_debug_dir = os.path.join(DEBUG_FRAMES_DIR, video_basename)\n",
        "        \n",
        "        # Process the video\n",
        "        result = process_altinha_video(\n",
        "            video_path=video_path,\n",
        "            model_path=BALL_MODEL_PATH,\n",
        "            output_path=output_video_path,\n",
        "            pose_model_path=POSE_MODEL_PATH,\n",
        "            debug_frames_dir=video_debug_dir,\n",
        "            verbose=True  # Set to False to reduce output\n",
        "        )\n",
        "        \n",
        "        # Store result\n",
        "        result['status'] = 'success'\n",
        "        result['error'] = None\n",
        "        all_results.append(result)\n",
        "        \n",
        "        print(f\"\\n‚úÖ Successfully processed: {os.path.basename(video_path)}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Error processing {os.path.basename(video_path)}: {str(e)}\")\n",
        "        all_results.append({\n",
        "            'video_name': os.path.basename(video_path),\n",
        "            'status': 'error',\n",
        "            'error': str(e),\n",
        "            'output_path': None,\n",
        "            'ball_detection_percentage': 0,\n",
        "            'total_hits': 0,\n",
        "            'head_hits': 0,\n",
        "            'foot_hits': 0,\n",
        "            'unknown_hits': 0,\n",
        "        })\n",
        "\n",
        "end_time = datetime.now()\n",
        "total_duration = (end_time - start_time).total_seconds()\n",
        "\n",
        "print(f\"\\n\\n{'#'*80}\")\n",
        "print(f\"#  BATCH PROCESSING COMPLETE\".ljust(79) + \"#\")\n",
        "print(f\"#  Total time: {total_duration:.1f} seconds\".ljust(79) + \"#\")\n",
        "print(\"#\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"BATCH PROCESSING SUMMARY\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Create summary DataFrame\n",
        "summary_data = []\n",
        "for result in all_results:\n",
        "    summary_data.append({\n",
        "        'Video': result['video_name'],\n",
        "        'Status': result['status'],\n",
        "        'Ball Detection %': f\"{result['ball_detection_percentage']:.1%}\" if result['status'] == 'success' else 'N/A',\n",
        "        'Total Hits': result['total_hits'],\n",
        "        'Head Hits': result['head_hits'],\n",
        "        'Foot Hits': result['foot_hits'],\n",
        "        'Unknown Hits': result['unknown_hits'],\n",
        "    })\n",
        "\n",
        "df_summary = pd.DataFrame(summary_data)\n",
        "print(df_summary.to_string(index=False))\n",
        "\n",
        "# Overall statistics\n",
        "successful = sum(1 for r in all_results if r['status'] == 'success')\n",
        "failed = len(all_results) - successful\n",
        "total_hits = sum(r['total_hits'] for r in all_results)\n",
        "avg_detection = sum(r['ball_detection_percentage'] for r in all_results if r['status'] == 'success') / successful if successful > 0 else 0\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"‚úÖ Successful: {successful}/{len(all_results)} videos\")\n",
        "print(f\"‚ùå Failed: {failed}/{len(all_results)} videos\")\n",
        "print(f\"‚öΩ Total hits across all videos: {total_hits}\")\n",
        "print(f\"üìä Average ball detection rate: {avg_detection:.1%}\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Batch Summary\n",
        "\n",
        "Save comprehensive JSON and CSV summaries of all processed videos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create batch summary\n",
        "batch_summary = {\n",
        "    'batch_info': {\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'total_videos': len(all_results),\n",
        "        'successful': successful,\n",
        "        'failed': failed,\n",
        "        'total_processing_time_sec': total_duration,\n",
        "    },\n",
        "    'aggregate_stats': {\n",
        "        'total_hits': total_hits,\n",
        "        'average_detection_percentage': round(avg_detection, 4),\n",
        "    },\n",
        "    'videos': []\n",
        "}\n",
        "\n",
        "# Add individual video results\n",
        "for result in all_results:\n",
        "    video_summary = {\n",
        "        'video_name': result['video_name'],\n",
        "        'status': result['status'],\n",
        "        'output_path': result.get('output_path'),\n",
        "        'json_path': result.get('json_path'),\n",
        "    }\n",
        "    \n",
        "    if result['status'] == 'success':\n",
        "        video_summary.update({\n",
        "            'ball_detection_percentage': round(result['ball_detection_percentage'], 4),\n",
        "            'total_hits': result['total_hits'],\n",
        "            'head_hits': result['head_hits'],\n",
        "            'foot_hits': result['foot_hits'],\n",
        "            'unknown_hits': result['unknown_hits'],\n",
        "            'hit_frames': [h['frame'] for h in result.get('hit_detections', [])],\n",
        "        })\n",
        "    else:\n",
        "        video_summary['error'] = result.get('error')\n",
        "    \n",
        "    batch_summary['videos'].append(video_summary)\n",
        "\n",
        "# Save batch summary JSON\n",
        "batch_summary_path = os.path.join(OUTPUT_DIR, 'batch_summary.json')\n",
        "with open(batch_summary_path, 'w') as f:\n",
        "    json.dump(batch_summary, f, indent=2)\n",
        "\n",
        "print(f\"\\nüìä Batch summary saved to: {batch_summary_path}\")\n",
        "\n",
        "# Save as CSV for easy viewing\n",
        "csv_path = os.path.join(OUTPUT_DIR, 'batch_summary.csv')\n",
        "df_summary.to_csv(csv_path, index=False)\n",
        "print(f\"üìä CSV summary saved to: {csv_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: Create a zip file of all results for easy download\n",
        "import shutil\n",
        "\n",
        "zip_path = '/kaggle/working/batch_results'\n",
        "shutil.make_archive(zip_path, 'zip', OUTPUT_DIR)\n",
        "\n",
        "print(f\"\\nüì¶ All results zipped to: {zip_path}.zip\")\n",
        "print(f\"   You can download this file from the output section.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
