{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "# Altinha Ball Tracking and Hit Detection\n",
    "\n",
    "This notebook performs ball tracking and hit detection on altinha (Brazilian footvolley) videos using YOLO object detection.\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/kifjj/altinha-play/blob/main/alta_infer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "Install required packages with specific versions for compatibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install \"numpy<2.0\" \"scipy<1.14\" supervision ultralytics \"opencv-python-headless<4.12\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T14:22:42.766837Z",
     "iopub.status.busy": "2025-11-22T14:22:42.766601Z",
     "iopub.status.idle": "2025-11-22T14:24:44.330220Z",
     "shell.execute_reply": "2025-11-22T14:24:44.328500Z",
     "shell.execute_reply.started": "2025-11-22T14:22:42.766814Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
      "Collecting scipy<1.14\n",
      "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting supervision\n",
      "  Downloading supervision-0.27.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.230-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting opencv-python-headless<4.12\n",
      "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0) (2025.3.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0) (2022.3.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0) (2.4.1)\n",
      "Requirement already satisfied: matplotlib>=3.6.0 in /usr/local/lib/python3.11/dist-packages (from supervision) (3.7.2)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from supervision) (6.0.3)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from supervision) (0.7.1)\n",
      "Requirement already satisfied: pillow>=9.4 in /usr/local/lib/python3.11/dist-packages (from supervision) (11.3.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from supervision) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.62.3 in /usr/local/lib/python3.11/dist-packages (from supervision) (4.67.1)\n",
      "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.11/dist-packages (from supervision) (4.12.0.88)\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (7.1.3)\n",
      "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.25.0)\n",
      "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision) (25.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision) (2.9.0.post0)\n",
      "INFO: pip is looking at multiple versions of opencv-python to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opencv-python>=4.5.5.64 (from supervision)\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->supervision) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->supervision) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->supervision) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->supervision) (2025.10.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0) (2025.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0) (2022.3.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0) (2024.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
      "Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading supervision-0.27.0-py3-none-any.whl (212 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m212.4/212.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics-8.3.230-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, scipy, opencv-python, ultralytics, supervision, opencv-python-headless\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.15.3\n",
      "    Uninstalling scipy-1.15.3:\n",
      "      Successfully uninstalled scipy-1.15.3\n",
      "  Attempting uninstall: opencv-python\n",
      "    Found existing installation: opencv-python 4.12.0.88\n",
      "    Uninstalling opencv-python-4.12.0.88:\n",
      "      Successfully uninstalled opencv-python-4.12.0.88\n",
      "  Attempting uninstall: opencv-python-headless\n",
      "    Found existing installation: opencv-python-headless 4.12.0.88\n",
      "    Uninstalling opencv-python-headless-4.12.0.88:\n",
      "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 opencv-python-4.11.0.86 opencv-python-headless-4.11.0.86 scipy-1.13.1 supervision-0.27.0 ultralytics-8.3.230 ultralytics-thop-2.0.18\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "from typing import Dict, List, Optional, Sequence, Tuple\n",
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up paths and hyperparameters for ball detection and hit counting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video and model paths\n",
    "VIDEO_PATH = '/kaggle/input/alta-videos/altinha-beach-green-mq-13s.mp4'\n",
    "MODEL_PATH = '/kaggle/input/yolo-ft-2511/pytorch/default/1/altinha_best.pt'\n",
    "OUTPUT_PATH = '/kaggle/working/altinha-beach-green-mq-BEST_ONLY.mp4'\n",
    "\n",
    "POSE_MODEL_PATH = '/kaggle/input/yolo11-pose/pytorch/default/1/yolo11n-pose.pt'\n",
    "\n",
    "# Debug output directory for hit frames\n",
    "DEBUG_FRAMES_DIR = '/kaggle/working/debug_frames'\n",
    "\n",
    "# Detection parameters\n",
    "CONFIDENCE_THRESHOLD = 0.05  # Minimum confidence for initial detection\n",
    "MIN_CONFIDENCE = 0.08  # Minimum confidence to keep a detection\n",
    "IOU_NMS = 0.5  # NMS IoU threshold\n",
    "\n",
    "# Hit detection parameters\n",
    "MIN_VERTICAL_AMPLITUDE = 3  # Minimum pixels for a valid hit (vertical movement)\n",
    "MIN_FRAMES_BETWEEN_HITS = 8  # Minimum frames between consecutive hits\n",
    "GAP_RESET_FRAMES = 30  # Frames without detection before resetting trajectory (1 sec at 30fps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Models and Annotators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Copy pose model to writable directory to avoid read-only file system error\n",
    "pose_model_writable = '/kaggle/working/yolo11n-pose.pt'\n",
    "if not os.path.exists(pose_model_writable):\n",
    "    shutil.copy(POSE_MODEL_PATH, pose_model_writable)\n",
    "\n",
    "# Load YOLO models\n",
    "model = YOLO(MODEL_PATH)\n",
    "model_pose = YOLO(pose_model_writable)  # Load from writable location\n",
    "\n",
    "# Setup annotators\n",
    "box_annotator = sv.BoxAnnotator(\n",
    "    thickness=2,\n",
    "    color=sv.Color.from_hex(\"#00FF00\")\n",
    ")\n",
    "\n",
    "label_annotator = sv.LabelAnnotator(\n",
    "    text_scale=0.5,\n",
    "    text_thickness=2,\n",
    "    text_position=sv.Position.TOP_CENTER,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Sequence, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "from ultralytics import YOLO\n",
    "\n",
    "BallPosition = Tuple[int, float, float, np.ndarray]\n",
    "HitDetections = List[Dict[str, object]]\n",
    "\n",
    "\n",
    "def filter_best_ball_detection(detections: sv.Detections, min_confidence: float) -> sv.Detections:\n",
    "    \"\"\"\n",
    "    Filter detections to keep only the best one (highest confidence).\n",
    "    \n",
    "    Args:\n",
    "        detections: sv.Detections object\n",
    "        min_confidence: Minimum confidence threshold\n",
    "        \n",
    "    Returns:\n",
    "        Filtered sv.Detections object (empty if no valid detection)\n",
    "    \"\"\"\n",
    "    if len(detections) == 0:\n",
    "        return detections\n",
    "    \n",
    "    best_idx = int(np.argmax(detections.confidence))\n",
    "    best_conf = float(detections.confidence[best_idx])\n",
    "    \n",
    "    if best_conf >= min_confidence:\n",
    "        return detections[best_idx:best_idx+1]\n",
    "    \n",
    "    return detections[0:0]  # Return empty detections\n",
    "\n",
    "\n",
    "def update_ball_tracking_state(\n",
    "    detections: sv.Detections,\n",
    "    n_frame: int,\n",
    "    last_ball_positions: List[BallPosition],\n",
    "    last_ball_detection_n_frame: Optional[int],\n",
    "    gap_reset_frames: int,\n",
    ") -> Tuple[List[BallPosition], Optional[int]]:\n",
    "    \"\"\"\n",
    "    Update ball tracking state with new detection.\n",
    "    \n",
    "    Args:\n",
    "        detections: sv.Detections object\n",
    "        n_frame: Current frame number\n",
    "        last_ball_positions: List of (frame_idx, x_center, y_center, bbox) tuples\n",
    "        last_ball_detection_n_frame: Last frame with detection\n",
    "        gap_reset_frames: Max gap before resetting trajectory\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (updated_last_positions, updated_last_detection_frame)\n",
    "    \"\"\"\n",
    "    if len(detections) == 0:\n",
    "        return last_ball_positions, last_ball_detection_n_frame\n",
    "    \n",
    "    # Check for gap in detections\n",
    "    if last_ball_detection_n_frame is not None:\n",
    "        gap = n_frame - last_ball_detection_n_frame\n",
    "        if gap > gap_reset_frames:\n",
    "            last_ball_positions = []\n",
    "    \n",
    "    # Get ball center and bbox\n",
    "    bbox = detections.xyxy[0]\n",
    "    x1, y1, x2, y2 = bbox.tolist()\n",
    "    x_center = 0.5 * (x1 + x2)\n",
    "    y_center = 0.5 * (y1 + y2)\n",
    "    \n",
    "    # Update position history (keep last 3)\n",
    "    last_ball_positions = last_ball_positions.copy()\n",
    "    last_ball_positions.append((n_frame, x_center, y_center, bbox))\n",
    "    if len(last_ball_positions) > 3:\n",
    "        last_ball_positions.pop(0)\n",
    "    \n",
    "    return last_ball_positions, n_frame\n",
    "\n",
    "\n",
    "def detect_hit(last_positions: List[BallPosition]) -> Tuple[bool, Optional[int], Optional[float], Optional[float], Optional[np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Detect if a hit occurred based on ball trajectory.\n",
    "    A hit is detected when the ball reaches a local maximum in y-coordinate (bottom of screen).\n",
    "    \n",
    "    Args:\n",
    "        last_positions: List of (frame_idx, x_center, y_center, bbox) tuples (last 3 positions)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (is_hit, frame_idx, y_center, vertical_span, bbox) or (False, None, None, None, None)\n",
    "    \"\"\"\n",
    "    if len(last_positions) != 3:\n",
    "        return False, None, None, None, None\n",
    "    \n",
    "    (f0, x0, y0, bbox0), (f1, x1c, y1c, bbox1c), (f2, x2c, y2c, bbox2c) = last_positions\n",
    "    \n",
    "    # Check if middle point is a local maximum (ball at lowest point)\n",
    "    going_down_then_up = (y0 < y1c) and (y2c < y1c)\n",
    "    vertical_span = y1c - min(y0, y2c)\n",
    "    \n",
    "    if going_down_then_up and vertical_span >= MIN_VERTICAL_AMPLITUDE:\n",
    "        return True, f1, y1c, vertical_span, bbox1c\n",
    "    \n",
    "    return False, None, None, None, None\n",
    "\n",
    "\n",
    "def get_pose_keypoints(frame: np.ndarray, model_pose: YOLO) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Run YOLO-pose model to detect player keypoints in the frame.\n",
    "    \n",
    "    Args:\n",
    "        frame: Video frame to analyze\n",
    "        model_pose: YOLO pose model\n",
    "        \n",
    "    Returns:\n",
    "        List of poses, each containing keypoints data\n",
    "    \"\"\"\n",
    "    results = model_pose(frame, verbose=False, conf=0.3)[0]\n",
    "    \n",
    "    if results.keypoints is None or len(results.keypoints.data) == 0:\n",
    "        return []\n",
    "    \n",
    "    # Extract keypoints data\n",
    "    # keypoints shape: (num_persons, num_keypoints, 3) where 3 = (x, y, confidence)\n",
    "    poses = []\n",
    "    for person_keypoints in results.keypoints.data:\n",
    "        poses.append(person_keypoints.cpu().numpy())\n",
    "    \n",
    "    return poses\n",
    "\n",
    "\n",
    "def find_closest_player(ball_center: Tuple[float, float], poses: Sequence[np.ndarray]) -> Tuple[Optional[np.ndarray], int]:\n",
    "    \"\"\"\n",
    "    Find the player closest to the ball.\n",
    "    \n",
    "    Args:\n",
    "        ball_center: Tuple (x, y) of ball center\n",
    "        poses: List of pose keypoints arrays\n",
    "        \n",
    "    Returns:\n",
    "        Tuple (player_pose, player_id) or (None, -1) if no players detected\n",
    "    \"\"\"\n",
    "    if not poses:\n",
    "        return None, -1\n",
    "    \n",
    "    ball_x, ball_y = ball_center\n",
    "    min_distance = float('inf')\n",
    "    closest_player_idx = -1\n",
    "    \n",
    "    print(f\"  [FIND_CLOSEST_PLAYER] Found {len(poses)} poses\")\n",
    "\n",
    "    for i, pose in enumerate(poses):\n",
    "        # Calculate player center from valid keypoints\n",
    "        valid_keypoints = pose[pose[:, 2] > 0.3]  # Filter by confidence > 0.3\n",
    "        if len(valid_keypoints) == 0:\n",
    "            continue\n",
    "        \n",
    "        player_x = np.mean(valid_keypoints[:, 0])\n",
    "        player_y = np.mean(valid_keypoints[:, 1])\n",
    "        \n",
    "        # Calculate distance to ball\n",
    "        distance = np.sqrt((ball_x - player_x)**2 + (ball_y - player_y)**2)\n",
    "        \n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_player_idx = i\n",
    "    \n",
    "    if closest_player_idx == -1:\n",
    "        return None, -1\n",
    "    \n",
    "    return poses[closest_player_idx], closest_player_idx\n",
    "\n",
    "\n",
    "def classify_hit_type(ball_bbox: np.ndarray, player_pose: Optional[np.ndarray]) -> str:\n",
    "    \"\"\"\n",
    "    Classify hit type (Head/Foot/Unknown) based on ball position and player keypoints.\n",
    "    \n",
    "    Args:\n",
    "        ball_bbox: Ball bounding box in xyxy format\n",
    "        player_pose: Player keypoint array (17, 3) with (x, y, confidence)\n",
    "        \n",
    "    Returns:\n",
    "        String: 'Head', 'Foot', or 'Unknown'\n",
    "    \"\"\"\n",
    "    if player_pose is None:\n",
    "        print(\"  [CLASSIFY] No player pose detected -> Unknown\")\n",
    "        return 'Unknown'\n",
    "    \n",
    "    # Calculate ball center\n",
    "    ball_x = (ball_bbox[0] + ball_bbox[2]) / 2\n",
    "    ball_y = (ball_bbox[1] + ball_bbox[3]) / 2\n",
    "\n",
    "    print(f\"\\n  [CLASSIFY] Ball position: x={ball_x:.1f}, y={ball_y:.1f}\")\n",
    "    \n",
    "    # COCO keypoint indices:\n",
    "    # Head: 0=nose, 3=left_ear, 4=right_ear\n",
    "    # Feet: 15=left_ankle, 16=right_ankle\n",
    "    head_indices = [0, 3, 4]\n",
    "    foot_indices = [15, 16]\n",
    "    head_names = ['nose', 'left_ear', 'right_ear']\n",
    "    foot_names = ['left_ankle', 'right_ankle']\n",
    "    \n",
    "    # Calculate distance to head keypoints\n",
    "    head_distances = []\n",
    "    print(f\"  [CLASSIFY] Head keypoints:\")\n",
    "    for idx, name in zip(head_indices, head_names):\n",
    "        if idx < len(player_pose) and player_pose[idx, 2] > 0.3:  # Check confidence\n",
    "            kp_x, kp_y, kp_conf = player_pose[idx, 0], player_pose[idx, 1], player_pose[idx, 2]\n",
    "            dist = np.sqrt((ball_x - kp_x)**2 + (ball_y - kp_y)**2)\n",
    "            head_distances.append(dist)\n",
    "            print(f\"    - {name:12s}: pos=({kp_x:.1f}, {kp_y:.1f}), conf={kp_conf:.2f}, dist={dist:.1f}\")\n",
    "        else:\n",
    "            conf_str = f\"{player_pose[idx, 2]:.2f}\" if idx < len(player_pose) else \"N/A\"\n",
    "            print(f\"    - {name:12s}: SKIPPED (conf={conf_str})\")\n",
    "    \n",
    "    # Calculate distance to foot keypoints\n",
    "    foot_distances = []\n",
    "    print(f\"  [CLASSIFY] Foot keypoints:\")\n",
    "    for idx, name in zip(foot_indices, foot_names):\n",
    "        if idx < len(player_pose) and player_pose[idx, 2] > 0.3:  # Check confidence\n",
    "            kp_x, kp_y, kp_conf = player_pose[idx, 0], player_pose[idx, 1], player_pose[idx, 2]\n",
    "            dist = np.sqrt((ball_x - kp_x)**2 + (ball_y - kp_y)**2)\n",
    "            foot_distances.append(dist)\n",
    "            print(f\"    - {name:12s}: pos=({kp_x:.1f}, {kp_y:.1f}), conf={kp_conf:.2f}, dist={dist:.1f}\")\n",
    "        else:\n",
    "            conf_str = f\"{player_pose[idx, 2]:.2f}\" if idx < len(player_pose) else \"N/A\"\n",
    "            print(f\"    - {name:12s}: SKIPPED (conf={conf_str})\")\n",
    "    \n",
    "    # Determine hit type based on minimum distances\n",
    "    min_head_dist = min(head_distances) if head_distances else float('inf')\n",
    "    min_foot_dist = min(foot_distances) if foot_distances else float('inf')\n",
    "    \n",
    "    print(f\"  [CLASSIFY] Min distances: head={min_head_dist:.1f}, foot={min_foot_dist:.1f}\")\n",
    "    \n",
    "    # If both are unavailable\n",
    "    if min_head_dist == float('inf') and min_foot_dist == float('inf'):\n",
    "        print(f\"  [CLASSIFY] No valid keypoints detected -> Unknown\")\n",
    "        return 'Unknown'\n",
    "    \n",
    "    # Classification with threshold (prefer the closer one with a margin)\n",
    "    distance_threshold = 80  # pixels - adjust based on video resolution\n",
    "    print(f\"  [CLASSIFY] Distance threshold: {distance_threshold} pixels\")\n",
    "    \n",
    "    # Decision logic\n",
    "    if min_head_dist < distance_threshold and min_head_dist < min_foot_dist:\n",
    "        print(f\"  [CLASSIFY] DECISION: Head (head_dist {min_head_dist:.1f} < threshold {distance_threshold} AND head_dist < foot_dist {min_foot_dist:.1f})\")\n",
    "        return 'Head'\n",
    "    elif min_foot_dist < distance_threshold:\n",
    "        print(f\"  [CLASSIFY] DECISION: Foot (foot_dist {min_foot_dist:.1f} < threshold {distance_threshold})\")\n",
    "        return 'Foot'\n",
    "    else:\n",
    "        print(f\"  [CLASSIFY] DECISION: Unknown (both distances exceed threshold: head={min_head_dist:.1f}, foot={min_foot_dist:.1f})\")\n",
    "        return 'Unknown'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def draw_debug_keypoints(frame: np.ndarray, player_pose: Optional[np.ndarray]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Draw small red boxes at nose, left ankle, and right ankle for debugging.\n",
    "    \n",
    "    Args:\n",
    "        frame: Video frame to annotate\n",
    "        player_pose: Player keypoint array (17, 3) with (x, y, confidence)\n",
    "        \n",
    "    Returns:\n",
    "        Annotated frame\n",
    "    \"\"\"\n",
    "    if player_pose is None:\n",
    "        return frame\n",
    "    \n",
    "    # COCO keypoint indices: 0=nose, 3=left_ear, 4=right_ear, 15=left_ankle, 16=right_ankle\n",
    "    keypoint_indices = [0, 3, 4, 15, 16]\n",
    "    keypoint_names = ['nose', 'left_ear', 'right_ear', 'left_ankle', 'right_ankle']\n",
    "    colors = [(0, 0, 255), (0, 0, 255), (0, 0, 255), (0, 0, 255), (0, 0, 255)]  # Red for all\n",
    "    \n",
    "    for idx, name, color in zip(keypoint_indices, keypoint_names, colors):\n",
    "        if idx < len(player_pose) and player_pose[idx, 2] > 0.3:  # Check confidence\n",
    "            kp_x, kp_y = int(player_pose[idx, 0]), int(player_pose[idx, 1])\n",
    "            \n",
    "            # Draw small red box (5x5 pixels)\n",
    "            box_size = 5\n",
    "            cv2.rectangle(\n",
    "                frame,\n",
    "                (kp_x - box_size, kp_y - box_size),\n",
    "                (kp_x + box_size, kp_y + box_size),\n",
    "                color,\n",
    "                thickness=2\n",
    "            )\n",
    "            \n",
    "            # Draw label next to the box\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                name,\n",
    "                (kp_x + box_size + 2, kp_y),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.4,\n",
    "                color,\n",
    "                1,\n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "    \n",
    "    return frame\n",
    "\n",
    "def check_and_record_hit(\n",
    "    last_ball_positions: List[BallPosition],\n",
    "    hit_detections: HitDetections,\n",
    "    fps: float,\n",
    "    min_frames_between_hits: int,\n",
    "    frame: np.ndarray,\n",
    "    model_pose: YOLO,\n",
    "    frame_buffer: Optional[Sequence[Tuple[int, np.ndarray]]] = None,\n",
    "    debug_dir: Optional[str] = None,\n",
    ") -> HitDetections:\n",
    "    \"\"\"\n",
    "    Check for hit and record it if valid, with hit type classification.\n",
    "    \n",
    "    Args:\n",
    "        last_positions: List of (frame_idx, x_center, y_center, bbox) tuples\n",
    "        hit_detections: List of hit metadata dicts\n",
    "        fps: Video frames per second\n",
    "        min_frames_between_hits: Minimum frames between consecutive hits\n",
    "        frame: Current video frame (fallback if frame_buffer lookup fails)\n",
    "        model_pose: YOLO pose model\n",
    "        frame_buffer: Optional list of (frame_idx, frame_image) tuples for debug output and frame retrieval\n",
    "        debug_dir: Optional directory to save debug frames\n",
    "        \n",
    "    Returns:\n",
    "        Updated hit_detections list\n",
    "    \"\"\"\n",
    "    is_hit, hit_n_frame, hit_y, span, hit_bbox = detect_hit(last_ball_positions)\n",
    "    \n",
    "    if is_hit:\n",
    "        # Check minimum gap between hits\n",
    "        last_hit_frame = hit_detections[-1]['frame'] if hit_detections else None\n",
    "        if not hit_detections or (hit_n_frame - last_hit_frame) >= min_frames_between_hits:\n",
    "            # Retrieve the correct frame from frame_buffer matching hit_n_frame\n",
    "            hit_frame = frame  # fallback to current frame\n",
    "            if frame_buffer is not None:\n",
    "                for frame_idx, frame_image in frame_buffer:\n",
    "                    if frame_idx == hit_n_frame:\n",
    "                        hit_frame = frame_image\n",
    "                        break\n",
    "            \n",
    "            # Analyze pose to classify hit type using the correct frame\n",
    "            poses = get_pose_keypoints(hit_frame, model_pose)\n",
    "            \n",
    "            ball_center = ((hit_bbox[0] + hit_bbox[2]) / 2, (hit_bbox[1] + hit_bbox[3]) / 2)\n",
    "            \n",
    "            player_pose, player_id = find_closest_player(ball_center, poses)\n",
    "            \n",
    "            hit_type = classify_hit_type(hit_bbox, player_pose)\n",
    "            \n",
    "            hit_detections = hit_detections.copy()\n",
    "            hit_detections.append({\n",
    "                'frame': hit_n_frame,\n",
    "                'type': hit_type,\n",
    "                'player_id': player_id,\n",
    "                'player_pose': player_pose  # Store pose for visualization\n",
    "            })\n",
    "            t_sec = hit_n_frame / fps\n",
    "            hit_number = len(hit_detections)\n",
    "            print(f\"HIT #{hit_number} at frame {hit_n_frame} (t={t_sec:.2f}s), Type: {hit_type}, Player: {player_id}, y={hit_y:.1f}, span={span:.1f}\")\n",
    "            \n",
    "            # Save debug frames if frame buffer is available\n",
    "            if frame_buffer is not None and debug_dir is not None:\n",
    "                save_debug_frames(frame_buffer, hit_n_frame, hit_number, debug_dir)\n",
    "            \n",
    "            return hit_detections\n",
    "    \n",
    "    return hit_detections\n",
    "\n",
    "\n",
    "def annotate_frame(\n",
    "    frame: np.ndarray,\n",
    "    detections: sv.Detections,\n",
    "    box_annotator: sv.BoxAnnotator,\n",
    "    label_annotator: sv.LabelAnnotator,\n",
    "    hit_detections: HitDetections,\n",
    "    n_frame: int,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Annotate frame with ball detection, hit counter, and debug keypoints.\n",
    "    \n",
    "    Args:\n",
    "        frame: Video frame to annotate\n",
    "        detections: sv.Detections object\n",
    "        box_annotator: Supervision box annotator\n",
    "        label_annotator: Supervision label annotator\n",
    "        hit_detections: List of hit metadata dicts\n",
    "        n_frame: Current frame number\n",
    "        \n",
    "    Returns:\n",
    "        Annotated frame\n",
    "    \"\"\"\n",
    "    annotated_frame = frame.copy()\n",
    "    \n",
    "    # Draw ball detection box and label\n",
    "    if len(detections) > 0:\n",
    "        conf = float(detections.confidence[0])\n",
    "        labels = [f\"Ball {conf:.2f}\"]\n",
    "        annotated_frame = box_annotator.annotate(\n",
    "            scene=annotated_frame,\n",
    "            detections=detections,\n",
    "        )\n",
    "        annotated_frame = label_annotator.annotate(\n",
    "            scene=annotated_frame,\n",
    "            detections=detections,\n",
    "            labels=labels,\n",
    "        )\n",
    "    \n",
    "    # Draw debug keypoints for the most recent hit (show for 10 frames after hit)\n",
    "    if hit_detections:\n",
    "        last_hit = hit_detections[-1]\n",
    "        frames_since_hit = n_frame - last_hit['frame']\n",
    "        if 0 <= frames_since_hit <= 10 and 'player_pose' in last_hit:\n",
    "            annotated_frame = draw_debug_keypoints(annotated_frame, last_hit['player_pose'])\n",
    "    \n",
    "    # Draw hit counter HUD\n",
    "    annotated_frame = draw_hit_counter(annotated_frame, hit_detections)\n",
    "    \n",
    "    return annotated_frame\n",
    "\n",
    "\n",
    "def draw_hit_counter(frame: np.ndarray, hit_detections: Sequence[Dict[str, object]]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Draw a hit counter HUD on the frame with breakdown by hit type.\n",
    "    \n",
    "    Args:\n",
    "        frame: Video frame to annotate\n",
    "        hit_detections: List of hit metadata dicts\n",
    "        \n",
    "    Returns:\n",
    "        Annotated frame\n",
    "    \"\"\"\n",
    "    # Calculate hit counts by type\n",
    "    total_hits = len(hit_detections)\n",
    "    head_hits = sum(1 for h in hit_detections if h['type'] == 'Head')\n",
    "    foot_hits = sum(1 for h in hit_detections if h['type'] == 'Foot')\n",
    "    unknown_hits = sum(1 for h in hit_detections if h['type'] == 'Unknown')\n",
    "    \n",
    "    hit_text = f\"Hits: {total_hits} | Head: {head_hits} | Foot: {foot_hits} | Unknown: {unknown_hits}\"\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 0.8\n",
    "    thickness = 2\n",
    "    \n",
    "    # Measure text size\n",
    "    (text_width, text_height), baseline = cv2.getTextSize(\n",
    "        hit_text, font, font_scale, thickness\n",
    "    )\n",
    "    \n",
    "    # Box position and padding\n",
    "    pad_x, pad_y = 10, 10\n",
    "    x1, y1 = 10, 10\n",
    "    x2 = x1 + text_width + 2 * pad_x\n",
    "    y2 = y1 + text_height + 2 * pad_y\n",
    "    \n",
    "    # Draw filled rectangle\n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 0), thickness=-1)\n",
    "    \n",
    "    # Draw text\n",
    "    text_x = x1 + pad_x\n",
    "    text_y = y1 + pad_y + text_height\n",
    "    cv2.putText(\n",
    "        frame, hit_text, (text_x, text_y),\n",
    "        font, font_scale, (0, 255, 0), thickness, cv2.LINE_AA\n",
    "    )\n",
    "    \n",
    "    return frame\n",
    "\n",
    "\n",
    "def save_debug_frames(\n",
    "    frame_buffer: Sequence[Tuple[int, np.ndarray]],\n",
    "    hit_frame: int,\n",
    "    hit_number: int,\n",
    "    debug_dir: str,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Save the 3 frames around a detected hit for debugging.\n",
    "    \n",
    "    Args:\n",
    "        frame_buffer: List of (frame_idx, frame_image) tuples\n",
    "        hit_frame: Frame number where the hit occurred\n",
    "        hit_number: Sequential hit number (1-indexed)\n",
    "        debug_dir: Directory to save debug frames\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    # Create debug directory if it doesn't exist\n",
    "    os.makedirs(debug_dir, exist_ok=True)\n",
    "    \n",
    "    # Find frames to save: hit_frame-1, hit_frame, hit_frame+1\n",
    "    frames_to_save = [hit_frame - 1, hit_frame, hit_frame + 1]\n",
    "    \n",
    "    for frame_idx, frame_image in frame_buffer:\n",
    "        if frame_idx in frames_to_save:\n",
    "            filename = f\"hit-{hit_number}-frame-{frame_idx}.png\"\n",
    "            filepath = os.path.join(debug_dir, filename)\n",
    "            cv2.imwrite(filepath, frame_image)\n",
    "            print(f\"  \ud83d\udcbe Saved debug frame: {filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_print_detections(detections: sv.Detections, n_frame: int) -> None:\n",
    "    if len(detections) > 0:\n",
    "        conf = float(detections.confidence[0])\n",
    "        x1, y1, x2, y2 = detections.xyxy[0].tolist()\n",
    "\n",
    "        print(\n",
    "            f\"FRAME {n_frame:4d}: best conf={conf:.3f}, \"\n",
    "            f\"bbox=({x1:.1f},{y1:.1f},{x2:.1f},{y2:.1f})\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"FRAME {n_frame:4d}: no detection\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Video\n",
    "\n",
    "Run ball detection and hit counting on the video.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get video info\n",
    "video_info = sv.VideoInfo.from_video_path(VIDEO_PATH)\n",
    "fps = video_info.fps\n",
    "frames_generator = sv.get_video_frames_generator(VIDEO_PATH)\n",
    "\n",
    "print(f\"Processing {VIDEO_PATH}\")\n",
    "print(f\"FPS: {fps}, Resolution: {video_info.width}x{video_info.height}\\n\")\n",
    "\n",
    "# Initialize tracking state\n",
    "last_ball_positions = []  # Track last 3 (frame_idx, x_center, y_center, bbox) positions\n",
    "hit_detections = []  # List of hit metadata dicts: {'frame': int, 'type': str, 'player_id': int}\n",
    "last_ball_detection_n_frame = None  # Last frame with a detection\n",
    "frame_buffer = []  # Buffer to keep last 3 frames for debug output\n",
    "previous_frame = None\n",
    "\n",
    "# Process video\n",
    "with sv.VideoSink(target_path=OUTPUT_PATH, video_info=video_info) as sink:\n",
    "    for n_frame, frame in enumerate(frames_generator, start=1):\n",
    "\n",
    "        if previous_frame is None:\n",
    "            previouse_frame = frame\n",
    "        \n",
    "        # Add current frame to buffer (keep last 3 frames)\n",
    "        frame_buffer.append((n_frame, frame.copy()))\n",
    "        if len(frame_buffer) > 3:\n",
    "            frame_buffer.pop(0)\n",
    "        \n",
    "        # Run YOLO detection\n",
    "        results = model(\n",
    "            frame,\n",
    "            verbose=False,\n",
    "            conf=CONFIDENCE_THRESHOLD,\n",
    "            iou=IOU_NMS,\n",
    "        )[0]\n",
    "        \n",
    "        ball_detections = sv.Detections.from_ultralytics(results)\n",
    "        \n",
    "        # Filter to keep only best detection\n",
    "        ball_detections = filter_best_ball_detection(ball_detections, MIN_CONFIDENCE)\n",
    "        \n",
    "        debug_print_detections(ball_detections, n_frame)\n",
    "\n",
    "        \n",
    "        # Update tracking state\n",
    "        last_ball_positions, last_ball_detection_n_frame = update_ball_tracking_state(\n",
    "            ball_detections, \n",
    "            n_frame, \n",
    "            last_ball_positions, \n",
    "            last_ball_detection_n_frame, \n",
    "            GAP_RESET_FRAMES\n",
    "        )\n",
    "        \n",
    "        # Check for hit and record it\n",
    "        if len(ball_detections) > 0:\n",
    "            hit_detections = check_and_record_hit(\n",
    "                last_ball_positions, \n",
    "                hit_detections, \n",
    "                fps, \n",
    "                MIN_FRAMES_BETWEEN_HITS, \n",
    "                previous_frame, \n",
    "                model_pose, \n",
    "                frame_buffer=frame_buffer,\n",
    "                debug_dir=DEBUG_FRAMES_DIR\n",
    "            )\n",
    "        \n",
    "        # Annotate frame with detections and hit counter\n",
    "        annotated_frame = annotate_frame(\n",
    "            frame, ball_detections, box_annotator, label_annotator, hit_detections, n_frame\n",
    "        )\n",
    "        \n",
    "        # Write frame to output video\n",
    "        sink.write_frame(annotated_frame)\n",
    "\n",
    "        previous_frame = frame\n",
    "\n",
    "print(f\"\\n\u2705 Done! Video saved to {OUTPUT_PATH}\")\n",
    "print(f\"\ud83d\udcca Total hits detected: {len(hit_detections)}\")\n",
    "print(f\"\ud83d\udc1b Debug frames saved to: {DEBUG_FRAMES_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary\n",
    "\n",
    "Display detailed results of hit detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"HIT DETECTION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calculate hit statistics\n",
    "total_hits = len(hit_detections)\n",
    "head_hits = sum(1 for h in hit_detections if h['type'] == 'Head')\n",
    "foot_hits = sum(1 for h in hit_detections if h['type'] == 'Foot')\n",
    "unknown_hits = sum(1 for h in hit_detections if h['type'] == 'Unknown')\n",
    "\n",
    "print(f\"Total hits/passes detected: {total_hits}\")\n",
    "print(f\"  - Head hits: {head_hits} ({100*head_hits/total_hits:.1f}%)\" if total_hits > 0 else \"  - Head hits: 0\")\n",
    "print(f\"  - Foot hits: {foot_hits} ({100*foot_hits/total_hits:.1f}%)\" if total_hits > 0 else \"  - Foot hits: 0\")\n",
    "print(f\"  - Unknown: {unknown_hits} ({100*unknown_hits/total_hits:.1f}%)\" if total_hits > 0 else \"  - Unknown: 0\")\n",
    "\n",
    "print(f\"\\nDetailed timestamps:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for i, hit_data in enumerate(hit_detections, start=1):\n",
    "    frame_idx = hit_data['frame']\n",
    "    hit_type = hit_data['type']\n",
    "    player_id = hit_data['player_id']\n",
    "    timestamp = frame_idx / fps\n",
    "    minutes = int(timestamp // 60)\n",
    "    seconds = timestamp % 60\n",
    "    print(f\"  Hit #{i:2d} | Frame {frame_idx:4d} | {minutes:02d}:{seconds:05.2f} | {hit_type:7s} | Player {player_id}\")\n",
    "\n",
    "print(\"=\" * 60)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNaAcP9Bd5f30t5hpdkTE8G",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8806920,
     "sourceId": 13828471,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 511911,
     "modelInstanceId": 496512,
     "sourceId": 656865,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}